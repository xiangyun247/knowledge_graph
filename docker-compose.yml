version: '3.8'

services:
  # ==================== Hadoop 集群 ====================
  
  # Hadoop NameNode（使用自定义镜像，包含 Python 和 pdfplumber）
  # 注意：此容器使用自定义 entrypoint，会在启动前自动清理重复配置
  # 详见: docker/hadoop-entrypoint.sh 和 HADOOP_CONFIG_CLEANUP_SOLUTION.md
  hadoop-namenode:
    build:
      context: .
      dockerfile: docker/Dockerfile.hadoop-python
    container_name: hadoop-namenode
    hostname: hadoop-namenode
    ports:
      - "9870:9870"  # NameNode Web UI
      - "9000:8020"  # HDFS 端口（外部:内部，Hadoop 3.x 使用 8020）
    environment:
      - CLUSTER_NAME=knowledge_graph
      - HADOOP_CONF_DIR=/hadoop/conf
    volumes:
      - namenode_data:/hadoop/dfs/name
      - ./hadoop/config:/hadoop/conf:ro
    networks:
      - kg-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9870"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Hadoop DataNode（使用自定义镜像，包含 Python 和 pdfplumber）
  # 注意：此容器使用自定义 entrypoint，会在启动前自动清理重复配置
  # 详见: docker/hadoop-entrypoint.sh 和 HADOOP_CONFIG_CLEANUP_SOLUTION.md
  hadoop-datanode:
    build:
      context: .
      dockerfile: docker/Dockerfile.hadoop-datanode-python
    container_name: hadoop-datanode
    hostname: hadoop-datanode
    ports:
      - "9864:9864"  # DataNode Web UI
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870
      - HADOOP_CONF_DIR=/hadoop/conf
    volumes:
      - datanode_data:/hadoop/dfs/data
      - ./hadoop/config:/hadoop/conf:ro
    networks:
      - kg-network
    depends_on:
      hadoop-namenode:
        condition: service_healthy

  # Hadoop ResourceManager
  # 注意：此容器使用官方镜像，entrypoint 脚本会在启动时追加配置
  # 如果发现重复配置，运行: python scripts/auto_clean_hadoop_configs.py
  hadoop-resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-resourcemanager
    hostname: hadoop-resourcemanager
    ports:
      - "8088:8088"  # YARN Web UI
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870
      - HADOOP_CONF_DIR=/hadoop/conf
    volumes:
      - ./hadoop/config:/hadoop/conf:ro # 挂载配置文件以便清理脚本访问
    networks:
      - kg-network
    depends_on:
      hadoop-namenode:
        condition: service_healthy

  # Hadoop NodeManager
  # 注意：此容器使用官方镜像，entrypoint 脚本会在启动时追加配置
  # 如果发现重复配置，运行: python scripts/auto_clean_hadoop_configs.py
  hadoop-nodemanager:
    build:
      context: .
      dockerfile: docker/Dockerfile.hadoop-nodemanager-python
    container_name: hadoop-nodemanager
    hostname: hadoop-nodemanager
    ports:
      - "8042:8042"
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870 hadoop-resourcemanager:8088
      - HADOOP_CONF_DIR=/hadoop/conf
    volumes:
      - ./hadoop/config:/hadoop/conf:ro
    networks:
      - kg-network
    depends_on:
      hadoop-namenode:
        condition: service_healthy
      hadoop-resourcemanager:
        condition: service_started

  # Hadoop HistoryServer（可选，用于查看任务历史）
  hadoop-historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-historyserver
    hostname: hadoop-historyserver
    ports:
      - "8188:8188"  # HistoryServer Web UI
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870,hadoop-resourcemanager:8088
    networks:
      - kg-network
    depends_on:
      - hadoop-namenode
      - hadoop-resourcemanager

  # ==================== 消息队列 ====================
  
  # Redis（Celery Broker）
  redis:
    image: redis:7-alpine
    container_name: kg-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - kg-network
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ==================== 数据库 ====================
  
  # Neo4j（若启动报错 exit 1，多为旧数据卷导致入口脚本二次初始化失败，可先删卷再起：docker volume rm knowledge_gragh_neo4j_data）
  neo4j:
    image: neo4j:5.15
    container_name: kg-neo4j
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-a2303548451}
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_server_memory_heap_initial__size=512m
      - NEO4J_server_memory_heap_max__size=512m
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    networks:
      - kg-network
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "${NEO4J_PASSWORD:-a2303548451}", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # MySQL（init_mysql.sql 创建并使用的库为 knowledge_graph_system，此处与之一致）
  mysql:
    image: mysql:8.0
    container_name: kg-mysql
    ports:
      - "3307:3306"  # 外部端口改为 3307，避免与本地 MySQL 冲突
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD:-root123}
      - MYSQL_DATABASE=knowledge_graph_system
      - MYSQL_USER=${MYSQL_USER:-kg_user}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD:-kg_password}
    volumes:
      - mysql_data:/var/lib/mysql
      - ./MYSQL/init_mysql.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - kg-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD:-root123}"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

  # ==================== 应用服务 ====================
  
  # FastAPI 后端
  backend:
    build:
      context: .
      dockerfile: docker/Dockerfile.backend
    container_name: kg-backend
    ports:
      - "5001:5001"
    environment:
      # Neo4j 配置
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-a2303548451}
      - NEO4J_DATABASE=neo4j
      # MySQL 配置
      - MYSQL_HOST=mysql
      - MYSQL_PORT=3306
      - MYSQL_USER=${MYSQL_USER:-kg_user}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD:-kg_password}
      - MYSQL_DATABASE=knowledge_graph_system
      # Redis 配置
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      # Hadoop 配置
      - HADOOP_NAMENODE=hadoop-namenode:8020
      - HADOOP_NAMENODE_UI=hadoop-namenode:9870
      # DeepSeek API（从 .env 文件读取，或在这里设置）
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY:-}
      - DEEPSEEK_BASE_URL=${DEEPSEEK_BASE_URL:-https://api.deepseek.com}
      - DEEPSEEK_MODEL=${DEEPSEEK_MODEL:-deepseek-chat}
      # 应用配置
      - DEBUG=${DEBUG:-False}
      - HOST=0.0.0.0
      - PORT=5001
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./backend:/app/backend
      - ./uploads:/app/uploads
      - ./logs:/app/logs
      - ./data:/app/data
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - kg-network
    depends_on:
      neo4j:
        condition: service_healthy
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      hadoop-namenode:
        condition: service_healthy
    restart: unless-stopped

  # Celery Worker
  celery-worker:
    build:
      context: .
      dockerfile: docker/Dockerfile.celery
    container_name: kg-celery-worker
    environment:
      # Neo4j 配置
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-a2303548451}
      - NEO4J_DATABASE=neo4j
      # MySQL 配置（任务可能写历史/图谱，与 backend 一致）
      - MYSQL_HOST=mysql
      - MYSQL_PORT=3306
      - MYSQL_USER=${MYSQL_USER:-kg_user}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD:-kg_password}
      - MYSQL_DATABASE=knowledge_graph_system
      # Redis 配置
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      # Hadoop 配置
      - HADOOP_NAMENODE=hadoop-namenode:8020
      # DeepSeek API
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY:-}
      - DEEPSEEK_BASE_URL=${DEEPSEEK_BASE_URL:-https://api.deepseek.com}
      - DEEPSEEK_MODEL=${DEEPSEEK_MODEL:-deepseek-chat}
      # 应用配置
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./backend:/app/backend
      - ./uploads:/app/uploads
      - ./logs:/app/logs
      - ./data:/app/data
    networks:
      - kg-network
    depends_on:
      redis:
        condition: service_healthy
      mysql:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      hadoop-namenode:
        condition: service_healthy
    command: celery -A backend.celery_app worker --loglevel=info --concurrency=4
    restart: unless-stopped

  # Celery Beat（定时任务，可选）
  celery-beat:
    build:
      context: .
      dockerfile: docker/Dockerfile.celery
    container_name: kg-celery-beat
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./backend:/app/backend
      - ./logs:/app/logs
    networks:
      - kg-network
    depends_on:
      - redis
    command: celery -A backend.celery_app beat --loglevel=info
    restart: unless-stopped

volumes:
  namenode_data:
    driver: local
  datanode_data:
    driver: local
  redis_data:
    driver: local
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  mysql_data:
    driver: local

networks:
  kg-network:
    driver: bridge


